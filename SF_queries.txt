STAGE

CREATE WAREHOUSE test WITH WAREHOUSE_SIZE = 'SMALL' WAREHOUSE_TYPE = 'STANDARD' AUTO_SUSPEND = 300 AUTO_RESUME = TRUE;

CREATE DATABASE ingest_data;

CREATE TABLE customer (
  customer_id STRING ,
  customer_name STRING ,
  customer_email STRING ,
  customer_city STRING ,
  customer_state STRING,
  customer_DOB DATE
  );

--sample data for the table above is present in AWS S3 at
s3://snowflake-essentials/ingesting_data/new_customer

create or replace stage bulk_copy_example_stage url='s3://snowflake-essentials/ingesting_data/new_customer';

list @bulk_copy_example_stage;

use database ingest_data;

copy into customer
  from @bulk_copy_example_stage
  pattern='*.csv'
  file_format = (type = csv field_delimiter = '|' skip_header = 1);

SELECT * FROM OUR_FIRST_TABLE;

SELECT COUNT(*) FROM OUR_FIRST_TABLE;
_________________________________________________________________________________________________________________
JSON LOAD

-- create a database if it doesn't already exist
CREATE DATABASE ingest_data;

USE DATABASE ingest_data;

-- create a table in which we will load the raw JSON data
CREATE TABLE organisations_json_raw (
  json_data_raw VARIANT
);

-- create an external stage using the S3 bucket that contains JSON data
CREATE OR REPLACE STAGE json_example_stage url='s3://snowflake-essentials/json_data';

-- list the files in the bucket
LIST @json_example_stage;

-- copy the example_json_file.json into the raw table
COPY INTO organisations_json_raw
  FROM @json_example_stage/example_json_file.json
  file_format = (type = json);
  
-- validate that the JSON has been loaded into the raw table
SELECT * FROM organisations_json_raw;
  
-- use the snowflake JSON capabilities to select value of a JSON attribute
SELECT 
	json_data_raw:data_set,
	json_data_raw:extract_date
FROM organisations_json_raw;
  
-- use flatten table function to conver the JSON data into column
SELECT
    value:name::String,
    value:state::String,
    value:org_code::String,
	json_data_raw:extract_date
FROM
    organisations_json_raw
    , lateral flatten( input => json_data_raw:organisations );
  
-- at this stage we can do a "create table as" to load the columnar data extracted from JSON
CREATE OR REPLACE TABLE organisations_ctas AS
SELECT
    VALUE:name::String AS org_name,
    VALUE:state::String AS state,
    VALUE:org_code::String AS org_code,
	json_data_raw:extract_date AS extract_date
FROM
    organisations_json_raw
    , lateral flatten( input => json_data_raw:organisations );

-- validate that the JSON data now indeed appears as proper table
SELECT * FROM organisations_ctas;

-- If you don't want to do a "create table as" you can pre-create a table
CREATE TABLE organisations (
    org_name STRING,
    state   STRING,
    org_code STRING,
	extract_date DATE
); 

-- and insert the JSON data into the table
INSERT INTO organisations 
SELECT
    VALUE:name::String AS org_name,
    VALUE:state::String AS state,
    VALUE:org_code::String AS org_code,
	json_data_raw:extract_date AS extract_date
FROM
    organisations_json_raw
    , lateral flatten( input => json_data_raw:organisations );

-- validate that the JSON data appears properly
SELECT * FROM organisations;
_________________________________________________________________________________________________________________
PIPE
-- create a database if it doesn't already exist
CREATE DATABASE ingest_data;

USE DATABASE ingest_data;


-- create an external stage using an S3 bucket
CREATE OR REPLACE STAGE snowpipe_copy_example_stage url='s3://snowpipe-streaming/transactions';

-- list the files in the bucket
LIST @snowpipe_copy_example_stage;

CREATE TABLE transactions
(

Transaction_Date DATE,
Customer_ID NUMBER,
Transaction_ID NUMBER,
Amount NUMBER
);

CREATE OR REPLACE PIPE transaction_pipe 
auto_ingest = true
AS COPY INTO transactions FROM @snowpipe_copy_example_stage
file_format = (type = csv field_delimiter = '|' skip_header = 1);

SELECT * FROM transactions;

SHOW PIPES;

-- setup S3 event notification here

SELECT COUNT(*) FROM transactions;
